üß≠ Build Plan ‚Äî Ephemeral Debian Devbox on EC2 Spot

Project guardrails (what we‚Äôre committing to)
	‚Ä¢	Bucket: devbox-backup (Restic repo)
	‚Ä¢	Config pin: Restic config snapshot ID stored in SSM
	‚Ä¢	Home restore: restore entire $HOME from the pinned snapshot (no staging/cleanup)
	‚Ä¢	Users/IDs: debian ‚Üí UID/GID 1000, ansible ‚Üí UID/GID 1001
	‚Ä¢	Storage: /home on ephemeral (instance-store/NVMe)
	‚Ä¢	Access: Tailscale with OIDC authentication (primary). Optional SSH troubleshooting via Terraform toggle.
	‚Ä¢	Networking: default VPC, public subnet, public IP, no inbound unless SSH toggle is on
	‚Ä¢	Lifecycle: one-time Spot instance; manual relaunch when you choose (no ASG)
	‚Ä¢	Safety: restic every 10 minutes; idle monitor terminates; interruption handler does a best-effort backup

‚∏ª

Phase 1 ‚Äî Repo & Structure
	1.	Scaffold project
	‚Ä¢	Folders: terraform/, ansible/, userdata/, docs/.
	‚Ä¢	Drop in README and this plan.
	2.	Decide naming & versions
	‚Ä¢	Snapshot tag convention: config, cfg-vNN.
	‚Ä¢	Optional MOTD shows current config tag and snapshot ID.

‚∏ª

Phase 2 ‚Äî S3 & Restic
	3.	S3 bucket
	‚Ä¢	Use devbox-backup for the Restic repo (versioning on).
	‚Ä¢	(Optional) Use prefixes only if you want, but tags drive behavior.
	4.	Initialize Restic repo
	‚Ä¢	Record repo URL and password (to be stored in SSM).
	‚Ä¢	Decide prune/forget policy (simple defaults are fine).

‚∏ª

Phase 3 ‚Äî SSM & KMS
	5.	Create SSM parameters (SecureString)
	‚Ä¢	/devserver/restic/repo
	‚Ä¢	/devserver/restic/password
	‚Ä¢	/devserver/restic/config_snapshot_id  ‚Üê pinned golden home snapshot
	‚Ä¢	/devserver/tailscale/client_id  ‚Üê OIDC client ID
	‚Ä¢	/devserver/tailscale/audience  ‚Üê OIDC audience (format: api.tailscale.com/{client_id})
	‚Ä¢	(Optional) /devserver/ssh_authorized_keys if you want to source keys from SSM
	6.	KMS & IAM boundary
	‚Ä¢	KMS key scoped to this project.
	‚Ä¢	Instance role needs:
	‚Ä¢	ssm:GetParameter + kms:Decrypt for the above
	‚Ä¢	s3:ListBucket/GetObject on arn:aws:s3:::devbox-backup/*
	‚Ä¢	sts:GetWebIdentityToken for Tailscale OIDC authentication

‚∏ª

Phase 4 ‚Äî Terraform (default VPC + SSH toggle)
	7.	Networking choices
	‚Ä¢	Use default VPC; select a public subnet.
	‚Ä¢	Ensure public IP assignment is on.
	8.	Security group design
	‚Ä¢	Outbound: allow all.
	‚Ä¢	Inbound: none by default.
	‚Ä¢	SSH toggle:
	‚Ä¢	Variable allow_ssh (default false).
	‚Ä¢	If true, open TCP 22 only to ssh_allowed_cidr (e.g., x.x.x.x/32).
	‚Ä¢	Optional ssh_key_name.
	9.	EC2 Spot instance
	‚Ä¢	Debian 12 AMI (arch of your choice).
	‚Ä¢	Spot request as one-time; instance_interruption_behavior = terminate.
	‚Ä¢	Root EBS small (8‚Äì16 GB).
	‚Ä¢	Select instance type with instance store (so /home can be ephemeral).
	‚Ä¢	InstanceInitiatedShutdownBehavior = terminate.
	10.	Instance role & profile
	‚Ä¢	Attach the least-privilege policy from Phase 3.
	11.	User data
	‚Ä¢	Reference the bootstrap script (see Phase 5 tasks).

‚∏ª

Phase 5 ‚Äî Bootstrap (cloud-init + Ansible)
	12.	User-data flow
	‚Ä¢	Install base tools (awscli, jq, python3).
	‚Ä¢	Create ansible (1001) with home /ansible (ops-only).
	‚Ä¢	Fetch Ansible content (from S3 or repo).
	‚Ä¢	Pull SSM parameters (restic repo, password, config snapshot ID, tailscale OIDC config).
	‚Ä¢	Hand off to Ansible.
	13.	Ansible responsibilities
	‚Ä¢	Ephemeral mount: format/mount instance store and bind/mount as /home.
	‚Ä¢	Create debian user with UID/GID 1000 (after /home is mounted).
	‚Ä¢	Restic restore (config snapshot): restore the pinned snapshot directly into /home/debian.
	‚Ä¢	System setup: install Docker, Python, Go, editors, build tools.
	‚Ä¢	Tailscale: install and authenticate using OIDC: `tailscale up --client-id=... --id-token=$(get-jwt.sh) --advertise-tags="tag:aws" --accept-routes`; optionally enable Tailscale SSH.
	‚Ä¢	SSH keys (optional): if SSH toggle is used, place authorized_keys (from SSM or your keypair).
	‚Ä¢	Ownership/permissions pass: verify sensitive paths (e.g., ~/.ssh) and mode bits.

‚∏ª

Phase 6 ‚Äî Backup & Lifecycle Automation
	14.	Recurring restic backup
	‚Ä¢	Systemd timer: every 10 minutes incremental snapshot.
	‚Ä¢	Tag as data (or no tag‚Äîconfig is already pinned elsewhere).
	‚Ä¢	Light excludes only if you truly don‚Äôt need big caches.
	15.	Idle monitor
	‚Ä¢	Timer + service: detect no logins/activity beyond threshold; skip if backup is running.
	‚Ä¢	On idle: trigger quick backup ‚Üí shutdown (maps to terminate).
	16.	Spot interruption handler
	‚Ä¢	Watch IMDS for 2-minute signal.
	‚Ä¢	On interrupt: quick incremental backup; log event.

‚∏ª

Phase 7 ‚Äî Config Baseline Lifecycle
	17.	Promote new baseline (when you choose)
	‚Ä¢	Quiesce if needed ‚Üí take full-home restic snapshot.
	‚Ä¢	Tag with config and a version (e.g., cfg-v13).
	‚Ä¢	Update SSM: /devserver/restic/config_snapshot_id to the new snapshot ID.
	‚Ä¢	Next relaunch adopts the new baseline.
	18.	Rollback
	‚Ä¢	Point SSM back to a prior config snapshot ID.
	‚Ä¢	Relaunch to return to that baseline.
	19.	Prove the loop
	‚Ä¢	Periodically test a clean relaunch:
	‚Ä¢	Verify ownership (1000/1000), Tailscale up, backups scheduled.

‚∏ª

Phase 8 ‚Äî Observability, Security, Docs
	20.	Logging
	‚Ä¢	Ship bootstrap, backup, idle, and interruption logs to CloudWatch.
	‚Ä¢	On boot, log: config snapshot ID, and timestamp of last successful data backup.
	21.	Security posture
	‚Ä¢	Keep allow_ssh=false in steady state.
	‚Ä¢	If true, restrict to /32, key-only, and disable once Tailscale is healthy.
	‚Ä¢	No public ingress otherwise; rely on Tailscale/SSM.
	22.	Docs & runbooks
	‚Ä¢	Short guides:
	‚Ä¢	Launch/Relaunch
	‚Ä¢	Promote Config
	‚Ä¢	Rollback
	‚Ä¢	Enable SSH Troubleshooting
	‚Ä¢	Where logs live

‚∏ª

Phase 9 ‚Äî Nice-to-haves (optional)
	23.	MOTD status
	‚Ä¢	Print config tag and snapshot ID, plus last backup time.
	24.	Make targets / simple CLI
	‚Ä¢	make launch, make promote-config, make rollback, make backup-now, make enable-ssh, make disable-ssh.
	25.	Health check
	‚Ä¢	Boot-time assertion: $HOME exists, owned by 1000:1000, Tailscale connected.

